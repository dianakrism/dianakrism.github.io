I"°<h2 id="project-team-id--ptid-cds-jul21-1171-members---diana-hema-pavithra-and-sophiya">Project Team ID = PTID-CDS-JUL21-1171 (Members - Diana, Hema, Pavithra and Sophiya)</h2>
<h2 id="project-id--prcp-1009-cellphoneprice-cellphone-price-range">Project ID = PRCP-1009-CellphonePrice (Cellphone Price Range)</h2>
<hr />

<h3 id="phase-1-loading-the-dataset-and-understanding-the-difference-features-and-target">Phase 1: Loading the Dataset and Understanding The Difference Features and Target</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">"ignore"</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span>  <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'datasets_11167_15520_train.csv'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>battery_power</th>
      <th>blue</th>
      <th>clock_speed</th>
      <th>dual_sim</th>
      <th>fc</th>
      <th>four_g</th>
      <th>int_memory</th>
      <th>m_dep</th>
      <th>mobile_wt</th>
      <th>n_cores</th>
      <th>...</th>
      <th>px_height</th>
      <th>px_width</th>
      <th>ram</th>
      <th>sc_h</th>
      <th>sc_w</th>
      <th>talk_time</th>
      <th>three_g</th>
      <th>touch_screen</th>
      <th>wifi</th>
      <th>price_range</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>842</td>
      <td>0</td>
      <td>2.2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>7</td>
      <td>0.6</td>
      <td>188</td>
      <td>2</td>
      <td>...</td>
      <td>20</td>
      <td>756</td>
      <td>2549</td>
      <td>9</td>
      <td>7</td>
      <td>19</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1021</td>
      <td>1</td>
      <td>0.5</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>53</td>
      <td>0.7</td>
      <td>136</td>
      <td>3</td>
      <td>...</td>
      <td>905</td>
      <td>1988</td>
      <td>2631</td>
      <td>17</td>
      <td>3</td>
      <td>7</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>563</td>
      <td>1</td>
      <td>0.5</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>41</td>
      <td>0.9</td>
      <td>145</td>
      <td>5</td>
      <td>...</td>
      <td>1263</td>
      <td>1716</td>
      <td>2603</td>
      <td>11</td>
      <td>2</td>
      <td>9</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>615</td>
      <td>1</td>
      <td>2.5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>10</td>
      <td>0.8</td>
      <td>131</td>
      <td>6</td>
      <td>...</td>
      <td>1216</td>
      <td>1786</td>
      <td>2769</td>
      <td>16</td>
      <td>8</td>
      <td>11</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1821</td>
      <td>1</td>
      <td>1.2</td>
      <td>0</td>
      <td>13</td>
      <td>1</td>
      <td>44</td>
      <td>0.6</td>
      <td>141</td>
      <td>2</td>
      <td>...</td>
      <td>1208</td>
      <td>1212</td>
      <td>1411</td>
      <td>8</td>
      <td>2</td>
      <td>15</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 21 columns</p>
</div>

<h3 id="description-of-the-dataset">Description of the Dataset</h3>

<h4 id="battery_powertotal-energy-a-battery-can-store-in-one-time-measured-in-mah">battery_power:Total energy a battery can store in one time measured in mAh</h4>
<h4 id="bluehas-bluetooth-or-not">blue:Has bluetooth or not</h4>
<h4 id="clock_speedspeed-at-which-microprocessor-executes-instructions">clock_speed:speed at which microprocessor executes instructions</h4>
<h4 id="dual_simhas-dual-sim-support-or-not">dual_sim:Has dual sim support or not</h4>
<h4 id="fcfront-camera-mega-pixels">fc:Front Camera mega pixels</h4>
<h4 id="four_ghas-4g-or-not">four_g:Has 4G or not</h4>
<h4 id="int_memoryinternal-memory-in-gigabytes">int_memory:Internal Memory in Gigabytes</h4>
<h4 id="m_depmobile-depth-in-cm">m_dep:Mobile Depth in cm</h4>
<h4 id="mobile_wtweight-of-mobile-phone">mobile_wt:Weight of mobile phone</h4>
<h4 id="n_coresnumber-of-cores-of-processor">n_cores:Number of cores of processor</h4>
<h4 id="pcprimary-camera-mega-pixels">pc:Primary Camera mega pixels</h4>
<h4 id="px_heightpixel-resolution-height">px_height:Pixel Resolution Height</h4>
<h4 id="px_widthpixel-resolution-width">px_width:Pixel Resolution Width</h4>
<h4 id="ramrandom-access-memory-in-megabytes">ram:Random Access Memory in Megabytes</h4>
<h4 id="sc_hscreen-height-of-mobile-in-cm">sc_h:Screen Height of mobile in cm</h4>
<h4 id="sc_wscreen-width-of-mobile-in-cm">sc_w:Screen Width of mobile in cm</h4>
<h4 id="talk_timelongest-time-that-a-single-battery-charge-will-last-when-you-are">talk_time:longest time that a single battery charge will last when you are</h4>
<h4 id="three_ghas-3g-or-not">three_g:Has 3G or not</h4>
<h4 id="touch_screenhas-touch-screen-or-not">touch_screen:Has touch screen or not</h4>
<h4 id="wifihas-wifi-or-not">wifi:Has wifi or not</h4>
<h4 id="price_range-three-classifications-could-be-high-range-mid-range-and-low-range-dont-know-how-the-target-is-scaled">price_range: three classifications could be high range, mid range and low range (dont know how the target is scaled)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"____________________________________________"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"            Info of The Dataset"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"____________________________________________"</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">info</span><span class="p">()</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>____________________________________________
            Info of The Dataset
____________________________________________
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 2000 entries, 0 to 1999
Data columns (total 21 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   battery_power  2000 non-null   int64  
 1   blue           2000 non-null   int64  
 2   clock_speed    2000 non-null   float64
 3   dual_sim       2000 non-null   int64  
 4   fc             2000 non-null   int64  
 5   four_g         2000 non-null   int64  
 6   int_memory     2000 non-null   int64  
 7   m_dep          2000 non-null   float64
 8   mobile_wt      2000 non-null   int64  
 9   n_cores        2000 non-null   int64  
 10  pc             2000 non-null   int64  
 11  px_height      2000 non-null   int64  
 12  px_width       2000 non-null   int64  
 13  ram            2000 non-null   int64  
 14  sc_h           2000 non-null   int64  
 15  sc_w           2000 non-null   int64  
 16  talk_time      2000 non-null   int64  
 17  three_g        2000 non-null   int64  
 18  touch_screen   2000 non-null   int64  
 19  wifi           2000 non-null   int64  
 20  price_range    2000 non-null   int64  
dtypes: float64(2), int64(19)
memory usage: 328.2 KB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>battery_power    0
blue             0
clock_speed      0
dual_sim         0
fc               0
four_g           0
int_memory       0
m_dep            0
mobile_wt        0
n_cores          0
pc               0
px_height        0
px_width         0
ram              0
sc_h             0
sc_w             0
talk_time        0
three_g          0
touch_screen     0
wifi             0
price_range      0
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">describe</span><span class="p">().</span><span class="n">T</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>battery_power</th>
      <td>2000.0</td>
      <td>1238.51850</td>
      <td>439.418206</td>
      <td>501.0</td>
      <td>851.75</td>
      <td>1226.0</td>
      <td>1615.25</td>
      <td>1998.0</td>
    </tr>
    <tr>
      <th>blue</th>
      <td>2000.0</td>
      <td>0.49500</td>
      <td>0.500100</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>clock_speed</th>
      <td>2000.0</td>
      <td>1.52225</td>
      <td>0.816004</td>
      <td>0.5</td>
      <td>0.70</td>
      <td>1.5</td>
      <td>2.20</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>dual_sim</th>
      <td>2000.0</td>
      <td>0.50950</td>
      <td>0.500035</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>fc</th>
      <td>2000.0</td>
      <td>4.30950</td>
      <td>4.341444</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>3.0</td>
      <td>7.00</td>
      <td>19.0</td>
    </tr>
    <tr>
      <th>four_g</th>
      <td>2000.0</td>
      <td>0.52150</td>
      <td>0.499662</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>int_memory</th>
      <td>2000.0</td>
      <td>32.04650</td>
      <td>18.145715</td>
      <td>2.0</td>
      <td>16.00</td>
      <td>32.0</td>
      <td>48.00</td>
      <td>64.0</td>
    </tr>
    <tr>
      <th>m_dep</th>
      <td>2000.0</td>
      <td>0.50175</td>
      <td>0.288416</td>
      <td>0.1</td>
      <td>0.20</td>
      <td>0.5</td>
      <td>0.80</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>mobile_wt</th>
      <td>2000.0</td>
      <td>140.24900</td>
      <td>35.399655</td>
      <td>80.0</td>
      <td>109.00</td>
      <td>141.0</td>
      <td>170.00</td>
      <td>200.0</td>
    </tr>
    <tr>
      <th>n_cores</th>
      <td>2000.0</td>
      <td>4.52050</td>
      <td>2.287837</td>
      <td>1.0</td>
      <td>3.00</td>
      <td>4.0</td>
      <td>7.00</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>pc</th>
      <td>2000.0</td>
      <td>9.91650</td>
      <td>6.064315</td>
      <td>0.0</td>
      <td>5.00</td>
      <td>10.0</td>
      <td>15.00</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>px_height</th>
      <td>2000.0</td>
      <td>645.10800</td>
      <td>443.780811</td>
      <td>0.0</td>
      <td>282.75</td>
      <td>564.0</td>
      <td>947.25</td>
      <td>1960.0</td>
    </tr>
    <tr>
      <th>px_width</th>
      <td>2000.0</td>
      <td>1251.51550</td>
      <td>432.199447</td>
      <td>500.0</td>
      <td>874.75</td>
      <td>1247.0</td>
      <td>1633.00</td>
      <td>1998.0</td>
    </tr>
    <tr>
      <th>ram</th>
      <td>2000.0</td>
      <td>2124.21300</td>
      <td>1084.732044</td>
      <td>256.0</td>
      <td>1207.50</td>
      <td>2146.5</td>
      <td>3064.50</td>
      <td>3998.0</td>
    </tr>
    <tr>
      <th>sc_h</th>
      <td>2000.0</td>
      <td>12.30650</td>
      <td>4.213245</td>
      <td>5.0</td>
      <td>9.00</td>
      <td>12.0</td>
      <td>16.00</td>
      <td>19.0</td>
    </tr>
    <tr>
      <th>sc_w</th>
      <td>2000.0</td>
      <td>5.76700</td>
      <td>4.356398</td>
      <td>0.0</td>
      <td>2.00</td>
      <td>5.0</td>
      <td>9.00</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>talk_time</th>
      <td>2000.0</td>
      <td>11.01100</td>
      <td>5.463955</td>
      <td>2.0</td>
      <td>6.00</td>
      <td>11.0</td>
      <td>16.00</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>three_g</th>
      <td>2000.0</td>
      <td>0.76150</td>
      <td>0.426273</td>
      <td>0.0</td>
      <td>1.00</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>touch_screen</th>
      <td>2000.0</td>
      <td>0.50300</td>
      <td>0.500116</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>wifi</th>
      <td>2000.0</td>
      <td>0.50700</td>
      <td>0.500076</td>
      <td>0.0</td>
      <td>0.00</td>
      <td>1.0</td>
      <td>1.00</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>price_range</th>
      <td>2000.0</td>
      <td>1.50000</td>
      <td>1.118314</td>
      <td>0.0</td>
      <td>0.75</td>
      <td>1.5</td>
      <td>2.25</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">[</span><span class="s">'price_range'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0    500
1    500
2    500
3    500
Name: price_range, dtype: int64
</code></pre></div></div>

<h4 id="teams-remarks-data-seems-to-be-balanced-for-each-of-the-classes-with-no-null-values-for-any-of-the-variables">Teams Remarks: Data seems to be balanced for each of the classes with no null values for any of the variables</h4>
<hr />

<h3 id="phase-2-data-preparation">Phase 2: Data Preparation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span>  <span class="n">LabelEncoder</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ENCODING THE ENTIRE DATA SET
</span><span class="n">label</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">label</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">)</span>
<span class="n">data1</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>battery_power</th>
      <th>blue</th>
      <th>clock_speed</th>
      <th>dual_sim</th>
      <th>fc</th>
      <th>four_g</th>
      <th>int_memory</th>
      <th>m_dep</th>
      <th>mobile_wt</th>
      <th>n_cores</th>
      <th>...</th>
      <th>px_height</th>
      <th>px_width</th>
      <th>ram</th>
      <th>sc_h</th>
      <th>sc_w</th>
      <th>talk_time</th>
      <th>three_g</th>
      <th>touch_screen</th>
      <th>wifi</th>
      <th>price_range</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>255</td>
      <td>0</td>
      <td>17</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>108</td>
      <td>1</td>
      <td>...</td>
      <td>18</td>
      <td>186</td>
      <td>963</td>
      <td>4</td>
      <td>7</td>
      <td>17</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>382</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>51</td>
      <td>6</td>
      <td>56</td>
      <td>2</td>
      <td>...</td>
      <td>738</td>
      <td>1099</td>
      <td>998</td>
      <td>12</td>
      <td>3</td>
      <td>5</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>48</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>39</td>
      <td>8</td>
      <td>65</td>
      <td>4</td>
      <td>...</td>
      <td>962</td>
      <td>901</td>
      <td>984</td>
      <td>6</td>
      <td>2</td>
      <td>7</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>88</td>
      <td>1</td>
      <td>20</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>8</td>
      <td>7</td>
      <td>51</td>
      <td>5</td>
      <td>...</td>
      <td>935</td>
      <td>954</td>
      <td>1055</td>
      <td>11</td>
      <td>8</td>
      <td>9</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>954</td>
      <td>1</td>
      <td>7</td>
      <td>0</td>
      <td>13</td>
      <td>1</td>
      <td>42</td>
      <td>5</td>
      <td>61</td>
      <td>1</td>
      <td>...</td>
      <td>928</td>
      <td>517</td>
      <td>499</td>
      <td>3</td>
      <td>2</td>
      <td>13</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>216</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>7</td>
      <td>26</td>
      <td>5</td>
      <td>...</td>
      <td>939</td>
      <td>1022</td>
      <td>180</td>
      <td>8</td>
      <td>4</td>
      <td>17</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>1064</td>
      <td>1</td>
      <td>21</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>37</td>
      <td>1</td>
      <td>107</td>
      <td>3</td>
      <td>...</td>
      <td>745</td>
      <td>1080</td>
      <td>732</td>
      <td>6</td>
      <td>10</td>
      <td>14</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>1027</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>34</td>
      <td>6</td>
      <td>28</td>
      <td>7</td>
      <td>...</td>
      <td>716</td>
      <td>834</td>
      <td>1158</td>
      <td>4</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>732</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>44</td>
      <td>0</td>
      <td>65</td>
      <td>4</td>
      <td>...</td>
      <td>283</td>
      <td>120</td>
      <td>266</td>
      <td>13</td>
      <td>10</td>
      <td>17</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>8</td>
      <td>1</td>
      <td>15</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>43</td>
      <td>8</td>
      <td>88</td>
      <td>5</td>
      <td>...</td>
      <td>413</td>
      <td>184</td>
      <td>1526</td>
      <td>14</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>2000 rows Ã— 21 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># splitting the data into X and Y so we can do feature selection
</span>
<span class="n">x</span>  <span class="o">=</span> <span class="n">data1</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'price_range'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data1</span><span class="p">[</span><span class="s">'price_range'</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">y</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \
0            255     0           17         0   1       0           5      5   
1            382     1            0         1   0       1          51      6   
2             48     1            0         1   2       1          39      8   
3             88     1           20         0   0       0           8      7   
4            954     1            7         0  13       1          42      5   

   mobile_wt  n_cores  pc  px_height  px_width   ram  sc_h  sc_w  talk_time  \
0        108        1   2         18       186   963     4     7         17   
1         56        2   6        738      1099   998    12     3          5   
2         65        4   6        962       901   984     6     2          7   
3         51        5   9        935       954  1055    11     8          9   
4         61        1  14        928       517   499     3     2         13   

   three_g  touch_screen  wifi  
0        0             0     1  
1        1             1     0  
2        1             1     0  
3        1             0     0  
4        1             1     0  





0    1
1    2
2    2
3    2
4    1
Name: price_range, dtype: int64
</code></pre></div></div>

<p><strong>Too much input variables will be decreasing the accuracy of models so using the feature selection technique to reduce the no. of input variables that contribute less to predicting the target</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># FEATURE SELECTION TECHNIQUE
</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">chi2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#apply SelectKBest class to extract top 10 best features
</span><span class="n">bestfeatures</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">score_func</span><span class="o">=</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">bestfeatures</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">dfscores</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">fit</span><span class="p">.</span><span class="n">scores_</span><span class="p">)</span>
<span class="n">dfcolumns</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1">#concat two dataframes for better visualization
</span><span class="n">featurescores</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dfcolumns</span><span class="p">,</span><span class="n">dfscores</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">featurescores</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Specs'</span><span class="p">,</span> <span class="s">'Score'</span><span class="p">]</span> <span class="c1">#naming the data
</span><span class="k">print</span><span class="p">(</span><span class="n">featurescores</span><span class="p">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="s">'Score'</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Specs          Score
13            ram  428852.649505
0   battery_power   16835.196948
12       px_width   12243.820689
11      px_height    9989.550625
8       mobile_wt     223.407824
6      int_memory      95.819130
15           sc_w      16.480319
14           sc_h      16.194553
16      talk_time      16.174231
9         n_cores      11.681721
</code></pre></div></div>

<p><strong>The top 10 features are now used to build the models for comparison</strong></p>

<p><strong>Modifying the dataset to include only these 10 important features</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">x</span><span class="p">[[</span><span class="s">'ram'</span><span class="p">,</span> <span class="s">'battery_power'</span><span class="p">,</span> <span class="s">'px_width'</span><span class="p">,</span><span class="s">'px_height'</span><span class="p">,</span><span class="s">'mobile_wt'</span><span class="p">,</span><span class="s">'int_memory'</span><span class="p">,</span><span class="s">'sc_w'</span><span class="p">,</span><span class="s">'sc_h'</span><span class="p">,</span><span class="s">'talk_time'</span><span class="p">,</span><span class="s">'n_cores'</span><span class="p">]].</span><span class="n">copy</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ram</th>
      <th>battery_power</th>
      <th>px_width</th>
      <th>px_height</th>
      <th>mobile_wt</th>
      <th>int_memory</th>
      <th>sc_w</th>
      <th>sc_h</th>
      <th>talk_time</th>
      <th>n_cores</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>963</td>
      <td>255</td>
      <td>186</td>
      <td>18</td>
      <td>108</td>
      <td>5</td>
      <td>7</td>
      <td>4</td>
      <td>17</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>998</td>
      <td>382</td>
      <td>1099</td>
      <td>738</td>
      <td>56</td>
      <td>51</td>
      <td>3</td>
      <td>12</td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>984</td>
      <td>48</td>
      <td>901</td>
      <td>962</td>
      <td>65</td>
      <td>39</td>
      <td>2</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1055</td>
      <td>88</td>
      <td>954</td>
      <td>935</td>
      <td>51</td>
      <td>8</td>
      <td>8</td>
      <td>11</td>
      <td>9</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>499</td>
      <td>954</td>
      <td>517</td>
      <td>928</td>
      <td>61</td>
      <td>42</td>
      <td>2</td>
      <td>3</td>
      <td>13</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<hr />

<h3 id="phase-3-exploratory-data-analysis">Phase 3: Exploratory Data Analysis</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Checking for the skewness and kurtosis for 10 selected features and target
</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of ram: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'ram'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of ram: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'ram'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of battery power: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'battery_power'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of battery power: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'battery_power'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Pixel Width: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'px_width'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Pixel Width: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'px_width'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Pixel Height: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'px_height'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Pixel Height: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'px_height'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Mobile Weight: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'mobile_wt'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Mobile Weight: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'mobile_wt'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Internal Memory: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'int_memory'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Internal Memory: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'int_memory'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Screen Width: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'sc_w'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Screen Width: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'sc_w'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Screen Height: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'sc_h'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Screen Height: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'sc_h'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Talking Time Performance: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'talk_time'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Talking Time Performance: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'talk_time'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Number Cores Processor: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'n_cores'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Number Cores Processor: %f"</span> <span class="o">%</span><span class="n">X</span><span class="p">[</span><span class="s">'n_cores'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Skewness of Price Range: %f"</span> <span class="o">%</span><span class="n">data1</span><span class="p">[</span><span class="s">'price_range'</span><span class="p">].</span><span class="n">skew</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Kurtosis of Price Range: %f"</span> <span class="o">%</span><span class="n">data1</span><span class="p">[</span><span class="s">'price_range'</span><span class="p">].</span><span class="n">kurt</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Skewness of ram: -0.001103
Kurtosis of ram: -1.171483
Skewness of battery power: 0.028115
Kurtosis of battery power: -1.206078
Skewness of Pixel Width: 0.029001
Kurtosis of Pixel Width: -1.198770
Skewness of Pixel Height: 0.237204
Kurtosis of Pixel Height: -1.090681
Skewness of Mobile Weight: 0.006558
Kurtosis of Mobile Weight: -1.210376
Skewness of Internal Memory: 0.057889
Kurtosis of Internal Memory: -1.216074
Skewness of Screen Width: 0.633787
Kurtosis of Screen Width: -0.389523
Skewness of Screen Height: -0.098884
Kurtosis of Screen Height: -1.190791
Skewness of Talking Time Performance: 0.009512
Kurtosis of Talking Time Performance: -1.218591
Skewness of Number Cores Processor: 0.003628
Kurtosis of Number Cores Processor: -1.229750
Skewness of Price Range: 0.000000
Kurtosis of Price Range: -1.360400
</code></pre></div></div>

<p><strong>Reference - <code class="language-plaintext highlighter-rouge">Skewness between -0.5 and 0.5: data fairly symmetrical. Skewness between -1 and â€“ 0.5 or between 0.5 and 1: data moderately skewed. Skewness is less than -1 or greater than 1: the data are highly skewed. Kurtosis bettween -2 and +2 are considered acceptable.</code></strong></p>

<p><strong>Teams Remarks: The Skewness and Kurtosis for all the predictor and target variables falls within the acceptable range.</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">figure</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="c1">#See the distrubution of the data
</span><span class="n">plt</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Distrubution of 10 Selected Features'</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'ram'</span><span class="p">],</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'battery_power'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'px_width'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'px_height'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'mobile_wt'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'int_memory'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'sc_w'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'sc_h'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'talk_time'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="s">'n_cores'</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'EDA - Distplot Visualization.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_25_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#slicing 10 selected features to display boxplot. reasons to do that: the range of some features are different
</span><span class="n">slice_X1</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s">'ram'</span><span class="p">,</span> <span class="s">'battery_power'</span><span class="p">,</span> <span class="s">'px_width'</span><span class="p">,</span> <span class="s">'px_height'</span><span class="p">,</span> <span class="s">'mobile_wt'</span><span class="p">]]</span>
<span class="n">slice_X1</span>
<span class="n">slice_X2</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="s">'int_memory'</span><span class="p">,</span> <span class="s">'sc_w'</span><span class="p">,</span> <span class="s">'sc_h'</span><span class="p">,</span> <span class="s">'talk_time'</span><span class="p">,</span> <span class="s">'n_cores'</span><span class="p">]]</span>
<span class="n">slice_X2</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>int_memory</th>
      <th>sc_w</th>
      <th>sc_h</th>
      <th>talk_time</th>
      <th>n_cores</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>7</td>
      <td>4</td>
      <td>17</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>51</td>
      <td>3</td>
      <td>12</td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>39</td>
      <td>2</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>8</td>
      <td>8</td>
      <td>11</td>
      <td>9</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>42</td>
      <td>2</td>
      <td>3</td>
      <td>13</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1995</th>
      <td>0</td>
      <td>4</td>
      <td>8</td>
      <td>17</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1996</th>
      <td>37</td>
      <td>10</td>
      <td>6</td>
      <td>14</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1997</th>
      <td>34</td>
      <td>1</td>
      <td>4</td>
      <td>3</td>
      <td>7</td>
    </tr>
    <tr>
      <th>1998</th>
      <td>44</td>
      <td>10</td>
      <td>13</td>
      <td>17</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1999</th>
      <td>43</td>
      <td>4</td>
      <td>14</td>
      <td>0</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
<p>2000 rows Ã— 5 columns</p>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Boxplot to check any outlier
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">"darkgrid"</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">slice_X1</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">"w"</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"Dark2"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">"darkgrid"</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">slice_X2</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">"w"</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"Dark2_r"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">"Boxplot of of 10 Selected Features"</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'EDA - Boxplot Visualization.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Checking...========================================</span><span class="se">\n</span><span class="s">Result: Outliers Not Found'</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="output_27_0.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Checking...========================================
Result: Outliers Not Found
</code></pre></div></div>

<p><strong><code class="language-plaintext highlighter-rouge">No significant outliers in the dataset</code></strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#combining the x (features) and y (target) to show the heatmap and pairplot analysis
</span>
<span class="n">xydata</span> <span class="o">=</span> <span class="n">data1</span><span class="p">[[</span><span class="s">'ram'</span><span class="p">,</span> <span class="s">'battery_power'</span><span class="p">,</span> <span class="s">'px_width'</span><span class="p">,</span><span class="s">'px_height'</span><span class="p">,</span><span class="s">'mobile_wt'</span><span class="p">,</span><span class="s">'int_memory'</span><span class="p">,</span><span class="s">'sc_w'</span><span class="p">,</span><span class="s">'sc_h'</span><span class="p">,</span><span class="s">'talk_time'</span><span class="p">,</span><span class="s">'n_cores'</span><span class="p">,</span> <span class="s">'price_range'</span><span class="p">]].</span><span class="n">copy</span><span class="p">()</span>

<span class="n">xydata</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ram</th>
      <th>battery_power</th>
      <th>px_width</th>
      <th>px_height</th>
      <th>mobile_wt</th>
      <th>int_memory</th>
      <th>sc_w</th>
      <th>sc_h</th>
      <th>talk_time</th>
      <th>n_cores</th>
      <th>price_range</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>963</td>
      <td>255</td>
      <td>186</td>
      <td>18</td>
      <td>108</td>
      <td>5</td>
      <td>7</td>
      <td>4</td>
      <td>17</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>998</td>
      <td>382</td>
      <td>1099</td>
      <td>738</td>
      <td>56</td>
      <td>51</td>
      <td>3</td>
      <td>12</td>
      <td>5</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>984</td>
      <td>48</td>
      <td>901</td>
      <td>962</td>
      <td>65</td>
      <td>39</td>
      <td>2</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1055</td>
      <td>88</td>
      <td>954</td>
      <td>935</td>
      <td>51</td>
      <td>8</td>
      <td>8</td>
      <td>11</td>
      <td>9</td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>499</td>
      <td>954</td>
      <td>517</td>
      <td>928</td>
      <td>61</td>
      <td>42</td>
      <td>2</td>
      <td>3</td>
      <td>13</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Heatmap to shows the correlation
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">xydata</span><span class="p">.</span><span class="n">corr</span><span class="p">(),</span><span class="n">cmap</span><span class="o">=</span><span class="s">'nipy_spectral'</span><span class="p">,</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Heatmap Shows The Relationship (correlation) Between Selected Features'</span><span class="p">,</span>
         <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'EDA - Heatmap Visualization.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_30_0.png" alt="png" /></p>

<p><strong>Teams Remarks: Ram dictates 92% of the price range classification. Screen width and screen height seem to be correlated, so we may merge them to reduce any dimensionality problems. For now we have decided to leave it in there for modelling purposes. No other major collinearlity issues</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#pairplot analysis
</span>
<span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">xydata</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'price_range'</span><span class="p">,</span> <span class="n">corner</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">'gnuplot'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'EDA - Pairplot Visualization.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_32_0.png" alt="png" /></p>

<p><strong>Teams remarks: As is evident from the pair plots, ram is going to be a significant variable to determine the decision boundaries for the models</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#checking to see y counts
</span>
<span class="n">y</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0    500
1    500
2    500
3    500
Name: price_range, dtype: int64
</code></pre></div></div>

<hr />

<h3 id="phase-4-modelling-strategy">Phase 4: Modelling Strategy</h3>

<p><strong>Given this is a classification problem for multiple classes, several models will be used for the comparitive analysis and the best model will be chosen for this project</strong></p>

<h4 id="model-1-k-means">Model 1: K Means</h4>
<h4 id="model-2-knn">Model 2: KNN</h4>
<h4 id="model-3-decision-tree">Model 3: Decision Tree</h4>
<h4 id="model-4-random-forest">Model 4: Random Forest</h4>
<h4 id="model-5-xg-boost">Model 5: XG Boost</h4>
<h4 id="model-6-svm-classification">Model 6: SVM Classification</h4>

<p><strong>Splitting the dataset into train and test data sets for validation</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span> <span class="c1">#stratify -&gt; it can reduce the variability of sample statistics
</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>((1340, 10), (660, 10), (1340,), (660,))
</code></pre></div></div>

<p><strong>Scaling the train and test datasets</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#feature scaling
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_fc</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_fc</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Model 1: K Means</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model building
</span>
<span class="n">kmeans_mod</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">()</span>

<span class="n">kmeans_mod</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">labels_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([1, 0, 0, ..., 0, 3, 1])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">kmeans_mod</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">()</span>
<span class="n">kmeans_mod</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_mod</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">Kmeansscore</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">)</span>
<span class="n">Kmeansscore</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">execution_time</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Program Executed in "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">execution_time</span><span class="p">),</span> <span class="s">'seconds'</span><span class="p">)</span> <span class="c1"># It returns time in seconds
#print(timedelta(seconds=end_time - start_time))
#print('Duration: {}'.format(end_time - start_time))
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Program Executed in 0.35800029999995786 seconds
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">kmeans_mod</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">()</span>
<span class="n">kmeans_mod</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">kmeans_mod</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_mod</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">Kmeansscore</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">)</span>
<span class="n">Kmeansscore</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">execution_time</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Program Executed in "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">execution_time</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="s">'seconds'</span><span class="p">)</span> <span class="c1"># It returns time in seconds
#print(timedelta(seconds=end_time - start_time))
#print('Duration: {}'.format(end_time - start_time))
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Program Executed in 0.39 seconds
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#scatterplot analysis
</span>
<span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">'ram'</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">'battery_power'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span> <span class="n">kmeans_mod</span><span class="p">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="p">[</span><span class="s">'orange'</span><span class="p">,</span> <span class="s">'blue'</span><span class="p">,</span> <span class="s">'red'</span><span class="p">,</span> <span class="s">'green'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">kmeans_mod</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">kmeans_mod</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'X'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s">'red'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'KMeans Scatterplot.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_48_0.png" alt="png" /></p>

<p><strong>Teams Remarks: Data seems to be overlapping quite a bit at the boundaries (no clear and distinct boundaries) so K Means does not do well in such scenarios as the neighbours are mingled near the boundaries</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">kmeans_mod</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([1, 0, 0, ..., 0, 3, 1])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#checking the model score
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">kmeans_mod</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">Kmeansscore</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">clusters</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s">'euclidean'</span><span class="p">)</span>
<span class="n">Kmeansscore</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.22549709096550374
</code></pre></div></div>

<p><strong>Pickling The Model (Save and Load The Model)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'kmeans_pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">kmeans_mod</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'kmeans_pickle'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">model_kmeans</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_kmeans</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1">#testing the model. reason: to make sure the pickle output showing the same as the current model
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([1, 0, 0, ..., 0, 3, 1])
</code></pre></div></div>

<p><strong>Teams Remarks: As expected the silhouette score is very low indicating that this modelling technique is not apt for this project</strong>
<em>__
__</em></p>

<p><strong>Model 2: KNN</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span>  <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model building
</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span> 

<span class="c1"># Search parameters
</span><span class="n">param</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Sets up GridSearchCV object and stores it in grid variable
</span><span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn</span><span class="p">,{</span><span class="s">'n_neighbors'</span><span class="p">:</span> <span class="n">param</span><span class="p">})</span>

<span class="c1"># Fits the grid object and gets the best model
</span><span class="n">best_knn</span> <span class="o">=</span> <span class="n">grid</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">).</span><span class="n">best_estimator_</span>

<span class="c1"># Displays the optimum model
</span><span class="n">best_knn</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>KNeighborsClassifier(n_neighbors=93)
</code></pre></div></div>

<p><strong><code class="language-plaintext highlighter-rouge">Grid search found the optimal k value to be 93, using that for the final model below and testing for accuracy</code></strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">93</span><span class="p">)</span>
<span class="n">knn</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">knn_predicted</span> <span class="o">=</span> <span class="n">knn</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">knn_conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">knn_predicted</span><span class="p">)</span>
<span class="n">knn_acc_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">knn_predicted</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"confusion matrix"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">knn_conf_matrix</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"-------------------------------------------"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy of K-NeighborsClassifier:"</span><span class="p">,</span><span class="n">knn_acc_score</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"-------------------------------------------"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">knn_predicted</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>confusion matrix
[[155  10   0   0]
 [  3 154   8   0]
 [  0  11 145   9]
 [  0   0  19 146]]
-------------------------------------------
Accuracy of K-NeighborsClassifier: 90.9090909090909 

-------------------------------------------
              precision    recall  f1-score   support

           0       0.98      0.94      0.96       165
           1       0.88      0.93      0.91       165
           2       0.84      0.88      0.86       165
           3       0.94      0.88      0.91       165

    accuracy                           0.91       660
   macro avg       0.91      0.91      0.91       660
weighted avg       0.91      0.91      0.91       660
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># prediction
</span>
<span class="n">knn_train_predict</span>  <span class="o">=</span> <span class="n">knn</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">knn_test_predict</span>   <span class="o">=</span> <span class="n">knn</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># training and testing accuracy scores
</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span> <span class="p">,</span><span class="n">knn_train_predict</span><span class="p">))</span>
<span class="n">KNNscore</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span><span class="n">knn_test_predict</span><span class="p">)</span>
<span class="n">KNNscore</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9097014925373135





0.9090909090909091
</code></pre></div></div>

<p><strong>Pickling The Model (Save and Load The Model)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'knn_pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'knn_pickle'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">model_knn</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_knn</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#testing the model. reason: to make sure the pickle output showing the same as the current model
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 1, 3, 3, 1, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 3, 2, 0, 3, 3, 0, 2,
       1, 1, 3, 3, 1, 0, 1, 3, 3, 1, 3, 3, 1, 2, 3, 1, 3, 3, 2, 2, 2, 3,
       2, 2, 2, 0, 3, 0, 0, 2, 0, 3, 1, 0, 1, 3, 2, 1, 0, 2, 2, 1, 0, 2,
       0, 2, 0, 0, 1, 2, 3, 1, 1, 0, 2, 1, 1, 3, 2, 1, 0, 1, 3, 1, 2, 0,
       0, 0, 0, 3, 3, 0, 2, 1, 3, 2, 3, 1, 0, 2, 2, 0, 0, 3, 2, 2, 1, 0,
       3, 2, 1, 1, 0, 1, 2, 3, 3, 2, 1, 0, 1, 0, 3, 2, 0, 0, 0, 2, 3, 1,
       2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 3, 2, 3, 2, 3, 0, 3, 1, 2, 1, 2, 1,
       2, 0, 0, 1, 3, 3, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 3, 2, 0, 3, 3, 1,
       1, 0, 1, 2, 1, 0, 2, 2, 1, 3, 2, 0, 2, 3, 3, 0, 1, 2, 2, 2, 3, 1,
       3, 0, 2, 2, 0, 3, 1, 1, 1, 3, 1, 2, 2, 1, 3, 2, 2, 3, 3, 2, 2, 0,
       1, 0, 3, 3, 3, 2, 0, 1, 3, 1, 3, 0, 3, 2, 0, 0, 2, 1, 0, 2, 0, 2,
       0, 1, 3, 3, 2, 0, 1, 1, 0, 0, 3, 0, 3, 2, 3, 1, 1, 1, 1, 1, 3, 1,
       0, 1, 0, 1, 1, 3, 1, 1, 2, 3, 3, 1, 2, 3, 2, 2, 1, 1, 1, 2, 1, 1,
       0, 3, 0, 3, 2, 1, 1, 3, 0, 2, 3, 0, 0, 0, 2, 1, 1, 2, 2, 3, 1, 1,
       1, 1, 0, 0, 1, 1, 2, 2, 2, 0, 2, 0, 2, 3, 3, 0, 2, 3, 0, 2, 3, 2,
       1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 3, 3, 1, 2, 2, 0, 0, 2, 3, 1,
       2, 2, 3, 2, 2, 3, 1, 0, 0, 3, 0, 3, 0, 0, 0, 3, 1, 3, 3, 2, 1, 1,
       1, 3, 0, 1, 1, 1, 1, 3, 0, 1, 1, 2, 0, 0, 2, 0, 2, 1, 2, 3, 2, 3,
       1, 2, 3, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0,
       2, 3, 1, 2, 3, 2, 3, 1, 3, 3, 2, 2, 2, 3, 1, 3, 2, 0, 3, 2, 0, 1,
       0, 2, 3, 0, 0, 0, 1, 0, 0, 1, 2, 1, 0, 1, 1, 2, 1, 2, 1, 1, 0, 1,
       3, 3, 0, 0, 1, 3, 2, 3, 3, 1, 1, 3, 1, 2, 1, 3, 2, 0, 2, 0, 1, 1,
       1, 3, 1, 3, 3, 1, 3, 2, 3, 3, 2, 1, 3, 2, 2, 3, 0, 1, 1, 0, 0, 2,
       2, 1, 1, 1, 3, 0, 0, 2, 3, 2, 2, 1, 1, 0, 1, 1, 0, 0, 1, 3, 2, 2,
       3, 1, 0, 1, 0, 0, 0, 0, 3, 1, 3, 3, 1, 0, 0, 1, 2, 2, 3, 0, 2, 1,
       2, 3, 2, 0, 1, 3, 2, 2, 3, 3, 3, 1, 3, 3, 2, 2, 1, 2, 0, 0, 0, 1,
       0, 3, 2, 0, 0, 2, 1, 0, 1, 0, 1, 3, 3, 0, 2, 3, 1, 0, 1, 3, 1, 2,
       2, 2, 0, 2, 3, 3, 3, 2, 2, 2, 2, 0, 2, 1, 3, 2, 1, 3, 2, 0, 2, 2,
       2, 3, 1, 1, 0, 3, 1, 3, 2, 1, 0, 1, 1, 2, 3, 0, 3, 0, 2, 0, 0, 0,
       1, 0, 1, 2, 3, 1, 0, 3, 0, 2, 2, 2, 2, 0, 2, 1, 1, 3, 2, 1, 1, 0],
      dtype=int64)
</code></pre></div></div>

<hr />

<p><strong>Model 3: Decision Tree</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model building
</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">Deci_Tree_model</span>  <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:[</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">],</span>
              <span class="s">'random_state'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span> 
             <span class="p">}</span>  

<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">Deci_Tree_model</span><span class="p">,</span><span class="n">parameters</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">grid</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 25 candidates, totalling 125 fits





GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),
             param_grid={'max_depth': [3, 5, 10, 20, 30],
                         'random_state': [0, 1, 2, 3, 4]},
             verbose=1)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># printing best parameters from the above grid analysis
</span>
<span class="k">print</span><span class="p">(</span><span class="n">grid</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'max_depth': 10, 'random_state': 3}
</code></pre></div></div>

<h4 id="grid-search-has-provided-the-best-parameters-for-the-tree-so-using-these-parameters-for-the-final-tree-below-the-depth-of-10-seems-to-be-ok-given-there-are-10-predictor-variables">Grid search has provided the best parameters for the tree, so using these parameters for the final tree below, the depth of 10 seems to be ok given there are 10 predictor variables</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model building
</span>
<span class="n">Deci_Tree_best_model</span>  <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model fitting to the datasets
</span>
<span class="n">Deci_Tree_best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span> <span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DecisionTreeClassifier(max_depth=10, random_state=3)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Training and testing of the model
</span>
<span class="n">train_predict</span>  <span class="o">=</span> <span class="n">Deci_Tree_best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">test_predict</span>   <span class="o">=</span> <span class="n">Deci_Tree_best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># checking the accuracy scores of the model
</span>
<span class="n">Deci_Tree_train_accuracyscore</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span> <span class="p">,</span><span class="n">train_predict</span><span class="p">)</span>
<span class="n">Deci_Tree_test_accuracyscore</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Deci_Tree_train_accuracyscore</span><span class="p">,</span> <span class="n">Deci_Tree_test_accuracyscore</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.994776119402985 0.8181818181818182
</code></pre></div></div>

<p><strong>Pickling The Model (Save and Load The Model)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'dec_tree_pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">Deci_Tree_best_model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'dec_tree_pickle'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">model_dectree</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_dectree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#testing the model. reason: to make sure the pickle output showing the same as the current model
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 2, 3, 2, 1, 3, 3, 1, 2, 2, 3, 3, 1, 1, 0, 3, 2, 0, 3, 3, 0, 2,
       1, 1, 3, 3, 2, 1, 1, 3, 3, 2, 3, 3, 1, 1, 3, 1, 2, 3, 2, 2, 2, 3,
       1, 3, 2, 0, 3, 1, 0, 2, 0, 3, 2, 0, 2, 3, 2, 1, 1, 2, 2, 0, 0, 2,
       1, 3, 0, 0, 0, 2, 3, 1, 2, 0, 2, 1, 1, 3, 3, 1, 1, 2, 3, 0, 2, 0,
       0, 0, 0, 3, 3, 0, 3, 1, 3, 2, 3, 1, 0, 3, 2, 0, 0, 3, 3, 2, 1, 0,
       2, 1, 1, 1, 1, 0, 2, 3, 3, 2, 0, 0, 1, 0, 3, 1, 1, 0, 0, 2, 3, 2,
       2, 1, 1, 0, 2, 1, 0, 2, 0, 0, 3, 2, 3, 2, 3, 0, 3, 1, 2, 1, 3, 1,
       2, 1, 0, 0, 3, 2, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 3, 2, 0, 3, 3, 2,
       1, 0, 1, 2, 1, 1, 2, 3, 0, 3, 3, 0, 2, 2, 3, 0, 1, 2, 2, 2, 3, 2,
       3, 0, 2, 2, 0, 3, 1, 1, 1, 3, 1, 2, 1, 1, 3, 2, 2, 3, 3, 1, 3, 0,
       1, 0, 3, 3, 3, 2, 0, 2, 2, 2, 3, 0, 3, 2, 0, 0, 2, 0, 1, 3, 0, 2,
       0, 2, 3, 3, 1, 0, 1, 1, 1, 0, 3, 0, 3, 2, 3, 1, 2, 1, 1, 1, 3, 1,
       0, 0, 0, 1, 1, 3, 2, 1, 2, 3, 3, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1,
       1, 3, 0, 3, 3, 1, 1, 3, 0, 2, 3, 0, 0, 0, 2, 1, 1, 2, 3, 3, 1, 0,
       1, 1, 0, 0, 0, 1, 3, 2, 1, 0, 2, 1, 2, 3, 2, 0, 3, 3, 0, 2, 2, 1,
       1, 0, 1, 2, 3, 0, 1, 0, 1, 0, 0, 2, 3, 3, 1, 2, 2, 0, 1, 2, 3, 1,
       2, 2, 3, 2, 3, 3, 1, 0, 0, 3, 0, 3, 0, 0, 0, 3, 1, 3, 3, 2, 2, 1,
       1, 3, 0, 1, 0, 1, 1, 3, 0, 1, 1, 3, 0, 0, 2, 0, 1, 1, 2, 3, 2, 3,
       1, 2, 3, 0, 3, 3, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 3, 2, 0, 0,
       2, 3, 2, 2, 3, 3, 3, 1, 2, 3, 2, 2, 2, 3, 0, 3, 3, 0, 3, 1, 0, 1,
       0, 3, 3, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 2, 1, 2, 1, 2, 1, 1, 0, 1,
       3, 2, 0, 0, 1, 3, 2, 3, 2, 1, 0, 2, 0, 3, 1, 3, 2, 0, 2, 0, 1, 1,
       1, 3, 1, 3, 3, 1, 3, 2, 3, 3, 2, 1, 3, 2, 2, 3, 0, 1, 1, 0, 0, 2,
       2, 1, 1, 1, 3, 1, 0, 2, 3, 2, 2, 1, 2, 0, 1, 2, 0, 0, 1, 3, 2, 2,
       3, 2, 0, 1, 0, 0, 0, 0, 3, 1, 3, 3, 2, 0, 0, 0, 2, 2, 3, 0, 1, 1,
       2, 2, 2, 0, 1, 3, 2, 2, 2, 3, 3, 1, 3, 2, 3, 2, 1, 2, 0, 0, 0, 0,
       0, 3, 2, 0, 0, 2, 1, 0, 1, 0, 1, 3, 3, 0, 3, 3, 1, 0, 1, 3, 1, 2,
       2, 2, 0, 2, 2, 3, 2, 2, 1, 3, 1, 1, 2, 1, 2, 2, 1, 3, 3, 0, 2, 2,
       2, 2, 2, 1, 0, 3, 1, 3, 2, 1, 0, 2, 1, 3, 3, 0, 2, 0, 2, 0, 0, 0,
       1, 0, 1, 2, 3, 2, 0, 3, 0, 2, 2, 2, 2, 0, 2, 1, 1, 3, 2, 0, 1, 0],
      dtype=int64)
</code></pre></div></div>

<p><strong>The accuracy score for test data seems to be lower than for KNN model</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># visualising the tree
</span>
<span class="n">feature_label</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">target_label</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">y</span><span class="p">.</span><span class="n">unique</span><span class="p">()]</span>
</code></pre></div></div>

<p><strong>Visualizing the decision tree</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">Deci_Tree_best_model</span><span class="p">,</span> 
                   <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_label</span><span class="p">,</span>  
                   <span class="n">class_names</span><span class="o">=</span><span class="n">target_label</span><span class="p">,</span>
                   <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'Decision Tree Visualization.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_85_0.png" alt="png" /></p>

<p><strong>Visualizing the decision boundary.</strong></p>

<p><strong>As the no. of dimensions is 10, reducing the no of dimensions to 2 using PCA to visualize a 2D plot of the boundaries</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># visualizing the decision regions
</span>
<span class="kn">from</span> <span class="nn">mlxtend.plotting</span> <span class="kn">import</span> <span class="n">plot_decision_regions</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">to_numpy</span><span class="p">()</span> <span class="c1">#changing df to numpy
</span><span class="n">b</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="n">Deci_Tree_best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="n">plot_decision_regions</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">Deci_Tree_best_model</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Adding axes annotations
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'ram'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'battery_power'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Decision Tree Boundaries'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'Decision Tree Boundaries (Using PCA).png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_88_0.png" alt="png" /></p>

<p><strong>The decision tree model does a better job of demarking the clustered boundaries when compared to the K Means model, hence the improved accuracy score</strong></p>

<hr />

<p><strong>Model 4: Random Forest</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model building
</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">RFmodel</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>  <span class="c1"># Hyperparameters tuning
</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">30</span><span class="p">],</span>
              <span class="s">'random_state'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
              <span class="s">'n_estimators'</span><span class="p">:[</span><span class="mi">10</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span>
              <span class="s">'criterion'</span><span class="p">:</span> <span class="p">[</span><span class="s">'entropy'</span><span class="p">,</span> <span class="s">'ginni'</span><span class="p">]</span>
             <span class="p">}</span>  

<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">RFmodel</span><span class="p">,</span><span class="n">parameters</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
<span class="n">grid</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 250 candidates, totalling 1250 fits





GridSearchCV(cv=5, estimator=RandomForestClassifier(),
             param_grid={'criterion': ['entropy', 'ginni'],
                         'max_depth': [5, 10, 15, 20, 30],
                         'n_estimators': [10, 30, 50, 70, 100],
                         'random_state': [0, 1, 2, 3, 4]},
             verbose=1)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Printing the best parameters
</span>
<span class="k">print</span><span class="p">(</span><span class="n">grid</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">grid</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 100, 'random_state': 2}
RandomForestClassifier(criterion='entropy', max_depth=20, random_state=2)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Building the best fit model using the parameters from the grid search
</span>
<span class="n">RFBmodel</span>  <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span> <span class="mi">20</span> <span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> 
<span class="n">RFBmodel</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RandomForestClassifier(max_depth=20, n_estimators=50, random_state=2)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Training and testing the model and checking accuracy scores
</span>
<span class="n">RFBtrain_predict</span>  <span class="o">=</span> <span class="n">RFBmodel</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">RFBtest_predict</span>   <span class="o">=</span> <span class="n">RFBmodel</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span> <span class="p">,</span><span class="n">RFBtrain_predict</span><span class="p">))</span>
<span class="n">RFscore</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span> <span class="n">RFBtest_predict</span><span class="p">)</span>
<span class="n">RFscore</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.0





0.896969696969697
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Visualizing the tree
</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">RFBmodel</span><span class="p">.</span><span class="n">estimators_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                   <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_label</span><span class="p">,</span>  
                   <span class="n">class_names</span><span class="o">=</span><span class="n">target_label</span><span class="p">,</span>
                   <span class="n">filled</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'Random Forest Visualization.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_94_0.png" alt="png" /></p>

<p><strong>Pickling The Model (Save and Load The Model)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'rf_pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">RFBmodel</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'rf_pickle'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">model_rf</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_rf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#testing the model. reason: to make sure the pickle output showing the same as the current model
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 2, 3, 2, 1, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 3, 2, 0, 3, 3, 0, 2,
       2, 1, 3, 3, 1, 0, 1, 3, 3, 1, 3, 3, 1, 1, 3, 1, 3, 3, 2, 2, 2, 3,
       1, 2, 2, 0, 3, 0, 1, 2, 0, 3, 2, 0, 1, 3, 2, 1, 0, 2, 2, 1, 0, 2,
       0, 2, 0, 0, 1, 1, 3, 1, 2, 0, 2, 1, 1, 3, 2, 1, 1, 2, 3, 1, 2, 0,
       0, 0, 0, 3, 3, 0, 3, 1, 3, 2, 3, 1, 0, 2, 2, 0, 0, 3, 3, 2, 1, 0,
       2, 1, 1, 0, 0, 0, 2, 3, 3, 2, 0, 0, 1, 0, 3, 2, 0, 0, 0, 2, 3, 1,
       2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 3, 2, 2, 2, 3, 0, 3, 1, 2, 1, 3, 1,
       2, 0, 0, 0, 3, 3, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 3, 2, 0, 3, 3, 2,
       1, 0, 1, 2, 1, 0, 2, 2, 1, 3, 3, 0, 2, 3, 3, 0, 1, 1, 2, 1, 3, 2,
       3, 0, 2, 2, 0, 3, 1, 1, 1, 3, 2, 2, 2, 1, 3, 2, 2, 3, 3, 1, 2, 0,
       1, 0, 3, 3, 3, 2, 0, 1, 3, 1, 3, 0, 3, 2, 0, 0, 2, 1, 1, 2, 0, 2,
       0, 1, 3, 3, 2, 0, 1, 1, 0, 0, 3, 0, 3, 2, 3, 0, 1, 1, 1, 1, 3, 1,
       0, 1, 0, 1, 1, 3, 1, 1, 2, 3, 3, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2,
       0, 3, 0, 3, 2, 1, 1, 3, 0, 2, 3, 0, 0, 0, 1, 2, 1, 2, 2, 3, 1, 1,
       1, 1, 0, 0, 1, 1, 2, 2, 1, 0, 2, 0, 2, 3, 3, 0, 2, 3, 0, 2, 2, 2,
       1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 3, 3, 1, 2, 2, 0, 0, 2, 3, 1,
       2, 2, 3, 2, 3, 3, 1, 0, 0, 3, 0, 3, 0, 0, 0, 3, 1, 3, 3, 2, 2, 1,
       1, 3, 0, 1, 0, 1, 1, 3, 0, 1, 1, 3, 0, 0, 2, 0, 1, 1, 2, 3, 2, 3,
       2, 2, 3, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0,
       2, 3, 2, 2, 3, 2, 3, 1, 3, 3, 1, 2, 2, 3, 1, 3, 3, 0, 3, 2, 0, 1,
       0, 2, 3, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 1, 1, 2, 0, 3, 1, 1, 0, 2,
       3, 3, 0, 0, 1, 3, 2, 3, 2, 1, 1, 3, 0, 3, 1, 3, 2, 0, 2, 0, 1, 1,
       1, 3, 1, 3, 3, 1, 3, 2, 3, 3, 2, 1, 3, 2, 2, 3, 0, 1, 1, 0, 0, 2,
       2, 1, 1, 1, 3, 1, 0, 2, 3, 2, 2, 1, 1, 0, 1, 1, 0, 0, 1, 3, 2, 2,
       3, 1, 0, 1, 0, 0, 0, 0, 3, 1, 3, 3, 1, 0, 0, 0, 3, 2, 3, 0, 2, 1,
       2, 3, 2, 0, 1, 3, 2, 2, 3, 3, 3, 1, 3, 2, 2, 2, 1, 2, 0, 0, 0, 0,
       0, 3, 2, 0, 0, 2, 1, 0, 0, 0, 1, 3, 3, 0, 2, 3, 1, 0, 1, 3, 1, 2,
       2, 2, 0, 2, 3, 3, 2, 2, 1, 3, 2, 0, 2, 1, 3, 2, 1, 3, 2, 0, 2, 2,
       2, 3, 1, 1, 0, 3, 1, 3, 2, 1, 0, 2, 1, 2, 3, 0, 3, 0, 3, 0, 0, 0,
       1, 1, 1, 2, 2, 1, 0, 3, 0, 2, 2, 3, 2, 0, 2, 1, 1, 3, 2, 0, 1, 0],
      dtype=int64)
</code></pre></div></div>

<hr />
<p><strong>Model 5: XG Boost</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#! pip install xgboost
# import XGBoost
</span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model building and using gridsearch to get the optimal parameters 
</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'objective'</span><span class="p">:</span><span class="s">'binary:logistic'</span><span class="p">,</span>
            <span class="s">'max_depth'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s">'learning_rate'</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="s">'n_estimators'</span><span class="p">:</span><span class="mi">100</span>
        <span class="p">}</span>         
      
        
<span class="c1"># instantiate the classifier 
</span><span class="n">xgb_clf</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>


<span class="c1"># fit the classifier to the training data
</span><span class="n">xgb_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[13:42:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.





XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,
              importance_type='gain', interaction_constraints='',
              learning_rate=1.0, max_delta_step=0, max_depth=4,
              min_child_weight=1, missing=nan, monotone_constraints='()',
              n_estimators=100, n_jobs=4, num_parallel_tree=1,
              objective='multi:softprob', random_state=0, reg_alpha=0,
              reg_lambda=1, scale_pos_weight=None, subsample=1,
              tree_method='exact', validate_parameters=1, verbosity=None)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Prediction using the best fit model and checking accuracy scores 
</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">xgb_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">XGBscore</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">XGBscore</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.9303030303030303
</code></pre></div></div>

<p><strong>Pickling The Model (Save and Load The Model)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'xgb_pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">xgb_clf</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'xgb_pickle'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">model_xgb</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_xgb</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#testing the model. reason: to make sure the pickle output showing the same as the current model
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 2, 3, 2, 1, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 3, 2, 0, 2, 3, 0, 2,
       2, 1, 3, 3, 1, 0, 1, 3, 3, 1, 3, 3, 1, 1, 3, 1, 3, 3, 2, 2, 2, 3,
       2, 2, 2, 0, 3, 0, 0, 2, 0, 3, 2, 0, 1, 3, 2, 0, 0, 2, 2, 1, 0, 2,
       0, 2, 0, 0, 1, 1, 3, 1, 1, 0, 2, 1, 2, 3, 2, 1, 1, 2, 3, 1, 2, 0,
       0, 0, 0, 3, 3, 0, 3, 1, 3, 2, 3, 1, 0, 2, 2, 0, 0, 3, 2, 2, 1, 0,
       2, 1, 1, 1, 0, 0, 2, 3, 3, 2, 0, 0, 1, 0, 3, 2, 0, 0, 0, 2, 3, 1,
       2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 3, 2, 3, 2, 3, 0, 3, 1, 2, 1, 2, 1,
       2, 0, 0, 1, 3, 3, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 3, 2, 0, 3, 3, 2,
       1, 0, 1, 2, 1, 0, 2, 2, 0, 3, 2, 0, 2, 3, 3, 0, 1, 2, 2, 2, 3, 1,
       3, 0, 2, 2, 0, 3, 1, 1, 1, 3, 1, 2, 2, 1, 3, 2, 2, 3, 3, 1, 2, 0,
       1, 0, 3, 3, 3, 2, 0, 1, 3, 1, 3, 0, 3, 2, 0, 0, 2, 1, 0, 2, 0, 2,
       0, 1, 3, 3, 1, 0, 2, 1, 0, 0, 3, 0, 3, 2, 3, 1, 2, 1, 1, 1, 3, 1,
       0, 1, 0, 1, 1, 3, 1, 1, 2, 3, 3, 1, 3, 3, 2, 1, 2, 1, 1, 2, 1, 2,
       0, 3, 0, 3, 3, 1, 1, 3, 0, 2, 3, 0, 0, 0, 2, 1, 1, 2, 3, 2, 1, 1,
       1, 1, 0, 0, 1, 1, 2, 2, 1, 0, 2, 0, 2, 3, 3, 0, 2, 3, 0, 2, 2, 2,
       1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 3, 3, 1, 2, 2, 0, 0, 1, 3, 1,
       2, 2, 3, 2, 3, 3, 1, 0, 0, 3, 0, 3, 0, 0, 0, 3, 1, 3, 3, 2, 1, 1,
       1, 3, 0, 1, 0, 1, 1, 3, 0, 1, 1, 3, 0, 0, 2, 0, 2, 1, 2, 3, 2, 3,
       1, 2, 3, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0,
       3, 3, 2, 2, 3, 2, 3, 1, 3, 3, 1, 2, 2, 3, 1, 3, 3, 0, 3, 1, 0, 1,
       0, 2, 3, 0, 0, 0, 1, 1, 0, 0, 3, 1, 0, 1, 1, 3, 1, 3, 1, 1, 0, 1,
       3, 3, 0, 0, 1, 3, 2, 3, 3, 1, 1, 2, 0, 3, 1, 3, 2, 0, 2, 0, 1, 1,
       2, 3, 1, 3, 3, 1, 3, 2, 3, 3, 2, 1, 3, 2, 2, 3, 0, 1, 1, 0, 0, 2,
       2, 1, 1, 1, 3, 0, 0, 2, 3, 2, 2, 1, 1, 0, 1, 1, 0, 0, 1, 3, 2, 2,
       3, 1, 0, 1, 0, 0, 0, 0, 3, 1, 3, 3, 2, 0, 0, 1, 3, 2, 3, 0, 2, 1,
       2, 3, 2, 0, 1, 3, 2, 2, 3, 3, 3, 1, 3, 2, 2, 2, 1, 2, 0, 0, 0, 1,
       0, 3, 2, 0, 0, 2, 1, 0, 0, 0, 1, 3, 3, 0, 2, 3, 1, 0, 1, 3, 1, 2,
       2, 2, 0, 3, 3, 3, 2, 2, 2, 2, 2, 0, 2, 1, 3, 2, 1, 3, 2, 0, 2, 2,
       2, 3, 1, 1, 0, 3, 1, 3, 2, 1, 0, 2, 1, 2, 3, 0, 3, 0, 3, 0, 0, 0,
       1, 0, 1, 2, 2, 1, 0, 3, 0, 2, 2, 3, 2, 0, 2, 1, 1, 3, 2, 0, 1, 0],
      dtype=int64)
</code></pre></div></div>

<hr />
<p><strong>Model 6: SVM Classification</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">mlxtend.plotting</span> <span class="kn">import</span> <span class="n">plot_decision_regions</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Building the best fit model using the gridsearch methodology
</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> 
              <span class="s">'gamma'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">],</span>
              <span class="s">'kernel'</span><span class="p">:</span> <span class="p">[</span><span class="s">'rbf'</span><span class="p">,</span> <span class="s">'poly'</span><span class="p">]}</span> 
  
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">refit</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
  
<span class="c1"># fitting the model for grid search
</span><span class="n">grid</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Fitting 5 folds for each of 50 candidates, totalling 250 fits
[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.313 total time=   0.2s
[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.306 total time=   0.2s
[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.313 total time=   0.2s
[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.299 total time=   0.2s
[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.500 total time=   0.2s
[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.500 total time=   0.2s
[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.496 total time=   0.2s
[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.496 total time=   0.2s
[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.683 total time=   0.2s
[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.265 total time=   0.1s
[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.257 total time=   0.1s
[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.261 total time=   0.2s
[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.265 total time=   0.1s
[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.272 total time=   0.1s
[CV 1/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ...C=0.1, gamma=0.001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.698 total time=   0.1s
[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.646 total time=   0.1s
[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.694 total time=   0.1s
[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.552 total time=   0.1s
[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.754 total time=   0.1s
[CV 1/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ..C=0.1, gamma=0.0001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.250 total time=   0.1s
[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.250 total time=   0.1s
[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.284 total time=   0.2s
[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.1s
[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.291 total time=   0.2s
[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.1s
[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.2s
[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.2s
[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.313 total time=   0.2s
[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.310 total time=   0.2s
[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.310 total time=   0.1s
[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.332 total time=   0.2s
[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.306 total time=   0.1s
[CV 1/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .....C=1, gamma=0.001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.1s
[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.896 total time=   0.1s
[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.892 total time=   0.1s
[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.825 total time=   0.2s
[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.858 total time=   0.1s
[CV 1/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ....C=1, gamma=0.0001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 1/5] END ........C=10, gamma=1, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ........C=10, gamma=1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ........C=10, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ........C=10, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ........C=10, gamma=1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.284 total time=   0.2s
[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.291 total time=   0.2s
[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 1/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ......C=10, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.2s
[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.1s
[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.1s
[CV 1/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .....C=10, gamma=0.01, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.2s
[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.2s
[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.321 total time=   0.1s
[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.1s
[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.1s
[CV 1/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ....C=10, gamma=0.001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.1s
[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.1s
[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.896 total time=   0.1s
[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.828 total time=   0.1s
[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.862 total time=   0.1s
[CV 1/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ...C=10, gamma=0.0001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 1/5] END .......C=100, gamma=1, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END .......C=100, gamma=1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .......C=100, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .......C=100, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .......C=100, gamma=1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.284 total time=   0.2s
[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.1s
[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.291 total time=   0.2s
[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 1/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .....C=100, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.1s
[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.1s
[CV 1/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ....C=100, gamma=0.01, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.2s
[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.1s
[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.321 total time=   0.2s
[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.2s
[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.1s
[CV 1/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ...C=100, gamma=0.001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.1s
[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.1s
[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.896 total time=   0.1s
[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.828 total time=   0.1s
[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.862 total time=   0.1s
[CV 1/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ..C=100, gamma=0.0001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.250 total time=   0.1s
[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.250 total time=   0.2s
[CV 1/5] END ......C=1000, gamma=1, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ......C=1000, gamma=1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ......C=1000, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ......C=1000, gamma=1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ......C=1000, gamma=1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.284 total time=   0.2s
[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.291 total time=   0.2s
[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.295 total time=   0.2s
[CV 1/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ....C=1000, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.2s
[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.250 total time=   0.2s
[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.254 total time=   0.2s
[CV 1/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ...C=1000, gamma=0.01, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.1s
[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.2s
[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.321 total time=   0.2s
[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.1s
[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.317 total time=   0.2s
[CV 1/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.970 total time=   0.1s
[CV 2/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END ..C=1000, gamma=0.001, kernel=poly;, score=0.929 total time=   0.0s
[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.1s
[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.1s
[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.896 total time=   0.1s
[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.828 total time=   0.1s
[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.862 total time=   0.1s
[CV 1/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.970 total time=   0.0s
[CV 2/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.948 total time=   0.0s
[CV 3/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 4/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.944 total time=   0.0s
[CV 5/5] END .C=1000, gamma=0.0001, kernel=poly;, score=0.929 total time=   0.0s





GridSearchCV(estimator=SVC(),
             param_grid={'C': [0.1, 1, 10, 100, 1000],
                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
                         'kernel': ['rbf', 'poly']},
             verbose=3)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># print best parameter after tuning
</span><span class="k">print</span><span class="p">(</span><span class="n">grid</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
  
<span class="c1"># print how our model looks after hyper-parameter tuning
</span><span class="k">print</span><span class="p">(</span><span class="n">grid</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'C': 0.1, 'gamma': 1, 'kernel': 'poly'}
SVC(C=0.1, gamma=1, kernel='poly')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Running the bestfit model and checking for accuracy scores
</span>
<span class="n">svc</span> <span class="o">=</span>  <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s">'poly'</span><span class="p">)</span>
<span class="n">svc</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">svc_predicted</span> <span class="o">=</span> <span class="n">svc</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">svc_conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc_predicted</span><span class="p">)</span>
<span class="n">svc_acc_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svc_predicted</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"confussion matrix"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">svc_conf_matrix</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"-------------------------------------------"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy of Support Vector Classifier:"</span><span class="p">,</span><span class="n">svc_acc_score</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"-------------------------------------------"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">svc_predicted</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>confussion matrix
[[162   3   0   0]
 [  2 158   5   0]
 [  0   2 155   8]
 [  0   0   5 160]]
-------------------------------------------
Accuracy of Support Vector Classifier: 96.21212121212122 

-------------------------------------------
              precision    recall  f1-score   support

           0       0.99      0.98      0.98       165
           1       0.97      0.96      0.96       165
           2       0.94      0.94      0.94       165
           3       0.95      0.97      0.96       165

    accuracy                           0.96       660
   macro avg       0.96      0.96      0.96       660
weighted avg       0.96      0.96      0.96       660
</code></pre></div></div>

<p><strong>Visualizing the classification boundaries for SVCâ€¦but since it is taking a long time to process the code has been commented</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#m = X_train.to_numpy() #changing df to numpy
#n = y_train.to_numpy()
</span>
<span class="c1">#plot_decision_regions(m, n,clf=svc, legend =4) 
</span>
<span class="c1"># Adding axes annotations
#plt.xlabel('ram')
#plt.ylabel('battery_power')
#plt.title('SVM Boundaries')
#plt.show()
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Training and testing the best fit model from the gridsearch
</span>
<span class="n">svc_train_predict</span>  <span class="o">=</span> <span class="n">svc</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">svc_test_predict</span>   <span class="o">=</span> <span class="n">svc</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># checking the accuracy of the best fit model
</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span> <span class="p">,</span><span class="n">svc_train_predict</span><span class="p">))</span>
<span class="n">SVCscore</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span> <span class="p">,</span><span class="n">svc_test_predict</span><span class="p">)</span>
<span class="n">SVCscore</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.0





0.9621212121212122
</code></pre></div></div>

<p><strong>Pickling The Model (Save and Load The Model)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'svc_pickle'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'svc_pickle'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">model_svc</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_svc</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1">#testing the model. reason: to make sure the pickle output showing the same as the current model
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 2, 3, 3, 1, 3, 3, 1, 2, 2, 3, 3, 2, 1, 0, 3, 2, 0, 3, 3, 0, 2,
       2, 1, 3, 3, 1, 0, 1, 3, 3, 1, 3, 3, 1, 1, 3, 1, 3, 3, 2, 2, 2, 3,
       2, 3, 2, 0, 3, 0, 0, 2, 0, 2, 1, 0, 1, 3, 2, 0, 0, 2, 2, 0, 0, 2,
       0, 2, 0, 0, 1, 2, 3, 1, 1, 0, 2, 1, 1, 3, 3, 1, 1, 1, 3, 1, 2, 0,
       0, 0, 0, 3, 3, 0, 3, 1, 3, 2, 3, 1, 0, 2, 2, 0, 0, 3, 2, 2, 1, 0,
       2, 2, 1, 1, 0, 0, 2, 3, 3, 2, 1, 0, 1, 0, 3, 2, 0, 0, 0, 2, 3, 1,
       2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 3, 2, 3, 2, 3, 0, 3, 1, 2, 1, 3, 1,
       2, 0, 0, 1, 3, 3, 2, 2, 2, 0, 2, 2, 1, 0, 1, 2, 3, 2, 0, 3, 3, 2,
       2, 0, 1, 2, 1, 0, 2, 2, 0, 3, 2, 0, 2, 3, 3, 0, 2, 2, 2, 2, 3, 1,
       3, 0, 2, 2, 0, 3, 1, 1, 1, 3, 1, 2, 2, 1, 3, 2, 3, 3, 3, 1, 2, 0,
       1, 0, 3, 3, 3, 2, 0, 1, 3, 1, 3, 0, 3, 2, 0, 0, 2, 1, 0, 3, 0, 2,
       0, 1, 3, 3, 2, 0, 2, 1, 0, 0, 3, 0, 3, 2, 3, 1, 1, 1, 1, 1, 3, 1,
       0, 1, 0, 1, 1, 3, 1, 1, 2, 3, 3, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1,
       0, 3, 0, 3, 3, 1, 2, 3, 0, 2, 3, 0, 0, 0, 2, 1, 1, 2, 3, 2, 1, 1,
       1, 1, 0, 0, 1, 1, 2, 2, 1, 0, 2, 0, 2, 3, 3, 0, 3, 3, 0, 2, 2, 2,
       1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 2, 3, 3, 1, 2, 2, 0, 0, 2, 3, 1,
       2, 2, 3, 2, 2, 3, 1, 0, 0, 3, 0, 3, 0, 0, 0, 3, 1, 3, 3, 2, 1, 1,
       1, 3, 0, 1, 1, 1, 1, 3, 0, 1, 1, 3, 0, 0, 2, 0, 2, 1, 2, 3, 2, 3,
       1, 2, 3, 0, 3, 3, 0, 3, 0, 0, 0, 3, 0, 0, 1, 0, 1, 0, 2, 2, 1, 0,
       2, 3, 2, 2, 3, 2, 3, 1, 3, 3, 1, 2, 2, 3, 1, 3, 3, 0, 3, 2, 0, 1,
       0, 2, 3, 0, 1, 0, 1, 0, 0, 0, 3, 1, 0, 1, 1, 3, 0, 3, 1, 1, 0, 1,
       3, 3, 0, 1, 1, 3, 2, 3, 3, 1, 1, 2, 0, 3, 1, 3, 2, 0, 2, 0, 1, 1,
       2, 3, 0, 3, 3, 1, 3, 3, 3, 3, 2, 1, 3, 2, 2, 3, 0, 1, 1, 0, 0, 2,
       2, 1, 1, 1, 3, 0, 0, 3, 3, 2, 2, 1, 2, 0, 1, 1, 0, 0, 1, 3, 2, 2,
       3, 1, 0, 1, 0, 0, 0, 0, 3, 1, 3, 3, 1, 0, 0, 1, 3, 2, 3, 0, 2, 1,
       2, 3, 2, 0, 1, 3, 2, 2, 3, 3, 3, 1, 3, 2, 2, 2, 1, 2, 0, 0, 0, 1,
       0, 3, 2, 0, 0, 2, 1, 0, 0, 0, 1, 3, 3, 0, 2, 3, 1, 0, 1, 3, 1, 2,
       2, 2, 0, 3, 3, 3, 2, 3, 2, 3, 2, 0, 2, 1, 3, 2, 1, 3, 2, 0, 2, 2,
       2, 2, 2, 1, 0, 3, 1, 3, 2, 1, 0, 2, 1, 2, 3, 0, 3, 0, 2, 0, 0, 0,
       1, 0, 1, 2, 2, 1, 0, 3, 0, 2, 2, 3, 2, 0, 2, 1, 1, 3, 2, 1, 1, 0],
      dtype=int64)
</code></pre></div></div>

<hr />
<h3 id="phase-5-summary-of-the-analysis-recommendation-project-risks">Phase 5: Summary of the Analysis, Recommendation, Project Risks</h3>
<p><strong>Summary of the Analysis</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Summary of the Accuracy scores for test data
</span><span class="n">model_ev</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'Model'</span><span class="p">:</span> <span class="p">[</span><span class="s">'K-Means'</span><span class="p">,</span><span class="s">'KNN'</span><span class="p">,</span><span class="s">'Decision Tree'</span><span class="p">,</span><span class="s">'Random Forest'</span><span class="p">,</span>
                    <span class="s">'XG Boost'</span><span class="p">,</span><span class="s">'SVM Classification'</span><span class="p">],</span> <span class="s">'Accuracy (%)'</span><span class="p">:</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">Kmeansscore</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                    <span class="nb">round</span><span class="p">(</span><span class="n">KNNscore</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="nb">round</span><span class="p">(</span><span class="n">Deci_Tree_test_accuracyscore</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="nb">round</span><span class="p">(</span><span class="n">RFscore</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="nb">round</span><span class="p">(</span><span class="n">XGBscore</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span><span class="nb">round</span><span class="p">(</span><span class="n">SVCscore</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]})</span>
<span class="n">model_ev</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>K-Means</td>
      <td>22.550</td>
    </tr>
    <tr>
      <th>1</th>
      <td>KNN</td>
      <td>90.909</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Decision Tree</td>
      <td>81.818</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Random Forest</td>
      <td>89.697</td>
    </tr>
    <tr>
      <th>4</th>
      <td>XG Boost</td>
      <td>93.030</td>
    </tr>
    <tr>
      <th>5</th>
      <td>SVM Classification</td>
      <td>96.212</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'red'</span><span class="p">,</span><span class="s">'green'</span><span class="p">,</span><span class="s">'blue'</span><span class="p">,</span><span class="s">'c'</span><span class="p">,</span><span class="s">'orange'</span><span class="p">,</span><span class="s">'yellow'</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Models Performance"</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Models"</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Accuracy (%)"</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s">'bold'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">model_ev</span><span class="p">[</span><span class="s">'Model'</span><span class="p">],</span><span class="n">model_ev</span><span class="p">[</span><span class="s">'Accuracy (%)'</span><span class="p">],</span><span class="n">color</span> <span class="o">=</span> <span class="n">colors</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'Models Performance.png'</span><span class="p">,</span> <span class="n">dpi</span> <span class="o">=</span> <span class="mi">300</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="output_122_0.png" alt="png" /></p>

<p><strong>SVM classification has the highest accuracy score</strong></p>

<p><strong>Recommendation</strong> <br /></p>
<ol>
  <li>SVM classification algorithm is the best modeling techinque for this project. This makes sense as the SVM methodology is the best technique for cluttered datasets with more than 3 dimensions. The data seems to be quite overlapping in 2D dimensions near the decision or classification boundaries (as seen in the 2D plots), but the SVM algorithm models the data at higher dimensions where the dataset can be linearly or distinctly divided into unique classes. Hence the higher scores.</li>
  <li>But the disadvantage is that it is very time and resource consuming to run the SVM model. The XG Boost Model gives a comparable accuracy score and takes a lesser time to run the model.</li>
  <li>The model can be further improved by eleminating or combining some of the correlated predictor variables like the (a) screen width and screen height, (b) pixel width and pixel height etc.</li>
  <li>Model can also be simplified and improved by using just the RAM of the cell phones for classification purposes instead of all other variables as RAM alone contributes to almost 92% of the target classification (as per correlation matrix).
<strong>To limit the scope of the analysis we have chosen not to implement Recommendations 3 &amp; 4.</strong></li>
</ol>

<p><strong>Project Risks</strong> <br /></p>
<ol>
  <li>We have taken the 10 best features from the feature selection algorithm to reduce the dimensionality problem for modelling purposes, so if there are any interaction effects between the features that have not been modelled, due to lack of expertise in this field, there may be considerable amount of underperformance in the model when it is implemented.</li>
  <li>The project assumes that the dataset used for modelling in this project is a representative of the population dataset else the models may not provide the accuracies that are shown here.</li>
</ol>
:ET